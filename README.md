# CodeAlpha Internship Projects

This repository contains three projects completed as part of the CodeAlpha internship. Each project applies machine learning techniques to solve real-world problems.

## Table of Contents
- [Project 1: Credit Scoring](#project-1-credit-scoring)
- [Project 2: Disease Prediction](#project-2-disease-prediction)
- [Project 3: Speech Emotion Recognition](#project-3-speech-emotion-recognition)

---

## Project 1: Credit Scoring model
This project focuses on evaluating an individual's creditworthiness using machine learning models. By analyzing financial history and other key factors, the model predicts the likelihood of a person defaulting on credit.

### Features:
- Data cleaning, transformation, and feature extraction.
- Developing machine learning models for credit risk evaluation.
- Assessing model accuracy and performance.

### Technologies Used:
- Python
- Scikit-learn
- Pandas
- NumPy

---

## Project 2: Disease Prediction
This project utilizes machine learning to predict the probability of a person having a specific disease based on their symptoms. The model is trained on medical datasets to classify diseases effectively.

### Features:
- Classification of diseases based on symptoms.
- Data preprocessing and model development.
- Optional implementation of a graphical user interface (GUI).
  
### Technologies Used:
- Python
- Scikit-learn
- Pandas

---

## Project 3: Speech Emotion Recognition
This project classifies emotions from speech using deep learning techniques. The model is trained on the RAVDESS dataset and deployed using Gradio for easy user interaction.

### Features:
- Extracts MFCC features from audio recordings.
- Uses a Convolutional Neural Network (CNN) for classification.
- Predicts emotions such as happy, sad, angry, neutral, etc.
- Implements a user-friendly interface with Gradio.

### Technologies Used:
- Python
- TensorFlow / Keras
- Librosa
- Gradio

### Dataset:
- **RAVDESS (Ryerson Audio-Visual Database of Emotional Speech and Song)**

### How It Works:
1. Extracts MFCC features from input speech.
2. Feeds the features into a CNN-based deep learning model.
3. Predicts and displays the detected emotion.
4. Users can upload an audio file or record their voice in real-time.

### Usage:
To run the project locally:
Download the ipynb file and install all the required libraries and execute it in an IDE
Then, access the Gradio interface in your browser.

---

## Conclusion
These projects demonstrate various applications of machine learning in finance, healthcare, and speech analysis. Each project showcases different techniques, from traditional ML models to deep learning-based audio classification.

Feel free to explore the code, contribute, or reach out with any questions!

